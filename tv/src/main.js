// Importaciones del sistema de archivos y utilidades de Node.js
import { promises as fs } from 'fs';
import path from 'path';
// Importaciones de configuraci√≥n y contenedor de servicios
import { EnvLoader } from './infrastructure/config/EnvLoader.js';
import TVAddonConfig from './infrastructure/config/TVAddonConfig.js';
import ChannelRepositoryFactory from './infrastructure/factories/ChannelRepositoryFactory.js';
import { ServiceContainer } from './infrastructure/container/ServiceContainer.js';
import { registerServices } from './infrastructure/container/ServiceRegistry.js';
import { BannedChannelsFilterService } from './domain/services/BannedChannelsFilterService.js';
import M3UChannelService from './application/M3UChannelService.js';
import ChannelNameCleaningService from './domain/services/ChannelNameCleaningService.js';
import LogoGenerationService from './services/LogoGenerationService.js';
import GenreDetectionService from './services/GenreDetectionService.js';

/**
 * Pipeline principal: Carga ‚Üí Filtrado ‚Üí Deduplicaci√≥n ‚Üí Conversi√≥n ‚Üí Validaci√≥n ‚Üí Archivos finales
 * Procesa canales IPTV desde m√∫ltiples fuentes y genera tv.csv + M3U para Stremio
 */
async function main() {
    const startTime = Date.now(); // Medici√≥n de tiempo total de procesamiento
    try {
        console.log('=== GENERADOR DE TV.CSV Y PLAYLIST M3U ===');
        console.log('Iniciando proceso de generaci√≥n autom√°tica...\n');

        // FASE 1: CONFIGURACI√ìN - Carga variables de entorno y configuraci√≥n centralizada
        console.log('üìã Paso 1: Cargando configuraci√≥n...');
        EnvLoader.getInstance(); // Singleton para cargar .env una sola vez
        const config = TVAddonConfig.getInstance(); // Configuraci√≥n centralizada del addon
        const logger = createLogger(); // Logger personalizado para trazabilidad
        
        console.log('‚úÖ Configuraci√≥n cargada correctamente\n');

        // FASE 2: INICIALIZACI√ìN - Instancia servicios seg√∫n configuraci√≥n
        console.log('üîß Paso 2: Inicializando servicios...');
        
        // Crear contenedor de servicios y registrar todas las dependencias
        const serviceContainer = new ServiceContainer(logger);
        registerServices(serviceContainer, config);
        
        // Resolver servicios desde el contenedor (sin dependencias circulares)
        const channelRepository = await ChannelRepositoryFactory.createRepository(config, logger);
        const deduplicationService = serviceContainer.resolve('channelDeduplicationService');
        const httpsToHttpService = serviceContainer.resolve('httpsToHttpService');
        const streamValidationService = serviceContainer.resolve('streamValidationService');
        const validatedChannelsCsvService = serviceContainer.resolve('validatedChannelsCsvService');
        const ipExtractionService = serviceContainer.resolve('ipExtractionService');
        const ipLatencyValidationService = serviceContainer.resolve('ipLatencyValidationService');
        
        console.log('‚úÖ Servicios inicializados correctamente desde contenedor IoC\n');

        // FASE 3: CARGA DE DATOS - Obtiene canales desde fuentes configuradas (CSV/M3U/H√≠brido)
        console.log('üì° Paso 3: Cargando canales desde fuentes...');
        const filteredChannels = await channelRepository.getAllChannels(); // Carga y filtra autom√°ticamente
        console.log(`üìä Canales cargados y filtrados: ${filteredChannels.length}`);
        
        // Estad√≠sticas de origen de canales para diagn√≥stico
        const sourceStats = getSourceStatistics(filteredChannels);
        logSourceStatistics(sourceStats);
        console.log('');

        // FASE 4: FILTRADO - Ya aplicado autom√°ticamente por el repositorio
        console.log('üîç Paso 4: Filtrado de contenido ya aplicado por el repositorio h√≠brido');
        console.log('');

        // FASE 5: PREPARACI√ìN DE DATOS - Asignar IDs √∫nicos para tracking consistente
        console.log('üîß Paso 5: Preparando datos para procesamiento...');
        const channelsWithIds = assignUniqueIds(filteredChannels);
        console.log(`‚úÖ IDs √∫nicos asignados a ${channelsWithIds.length} canales\n`);

        // FASE 6: PROCESAMIENTO CORE PARALELO - Deduplicaci√≥n, conversi√≥n y validaci√≥n
        console.log('üîÑ Paso 6: Procesamiento core paralelo (deduplicaci√≥n, conversi√≥n, validaci√≥n)...');
        
        // Separar operaciones cr√≠ticas de las opcionales para fail-fast apropiado
        let deduplicatedResult, conversionResult, validationResult;
        
        try {
            // OPERACIONES CR√çTICAS: Usar Promise.all para fail-fast en errores de configuraci√≥n/servicio
            const [deduplicationPromise, conversionPromise] = await Promise.all([
                // Deduplicaci√≥n: Cr√≠tica para evitar duplicados - debe fallar r√°pido si hay error de configuraci√≥n
                deduplicationService.deduplicateChannels(channelsWithIds).catch(error => {
                    if (error.message?.includes('configuration') || error.message?.includes('service') || error.name === 'ConfigurationError') {
                        console.error('‚ùå ERROR CR√çTICO en deduplicaci√≥n - Interrumpiendo procesamiento:', error.message);
                        throw error; // Fail-fast para errores cr√≠ticos
                    }
                    console.warn('‚ö†Ô∏è  Error no cr√≠tico en deduplicaci√≥n, continuando:', error.message);
                    return { channels: channelsWithIds, stats: { duplicatesRemoved: 0 } }; // Fallback graceful
                }),
                
                // Conversi√≥n: Cr√≠tica para compatibilidad - debe fallar r√°pido si hay error de servicio
                httpsToHttpService.processChannels(channelsWithIds).catch(error => {
                    if (error.message?.includes('configuration') || error.message?.includes('service') || error.name === 'ConfigurationError') {
                        console.error('‚ùå ERROR CR√çTICO en conversi√≥n - Interrumpiendo procesamiento:', error.message);
                        throw error; // Fail-fast para errores cr√≠ticos
                    }
                    console.warn('‚ö†Ô∏è  Error no cr√≠tico en conversi√≥n, continuando:', error.message);
                    return { processed: channelsWithIds, stats: { converted: 0, httpWorking: 0 } }; // Fallback graceful
                })
            ]);
            
            deduplicatedResult = { status: 'fulfilled', value: deduplicationPromise };
            conversionResult = { status: 'fulfilled', value: conversionPromise };
            
            // OPERACI√ìN OPCIONAL: Validaci√≥n puede fallar sin interrumpir el flujo completo
            try {
                const validationPromise = config.validation?.enableStreamValidation 
                    ? await streamValidationService.validateChannelsParallel(channelsWithIds, {
                        concurrency: 15,
                        maxBatchSize: 30,
                        showProgress: true
                      })
                    : { validChannels: channelsWithIds, invalidChannels: [], stats: {} };
                
                validationResult = { status: 'fulfilled', value: validationPromise };
            } catch (validationError) {
                console.warn('‚ö†Ô∏è  Error en validaci√≥n (no cr√≠tico), continuando sin validaci√≥n:', validationError.message);
                validationResult = { 
                    status: 'rejected', 
                    reason: validationError,
                    fallback: { validChannels: channelsWithIds, invalidChannels: [], stats: {} }
                };
            }
            
        } catch (criticalError) {
            console.error('üí• ERROR CR√çTICO en procesamiento core - Sistema debe detenerse:', criticalError.message);
            console.error('üîß Verifique la configuraci√≥n de servicios y dependencias');
            throw criticalError; // Fail-fast para errores cr√≠ticos de configuraci√≥n/servicio
        }

        // Consolidar resultados del procesamiento core
        const coreProcessingResults = processParallelResults(
            channelsWithIds,
            { deduplicatedResult, conversionResult, validationResult }
        );
        
        console.log('‚úÖ Procesamiento core completado\n');

        // FASE 7: PROCESAMIENTO POR CHUNKS - Limpieza, g√©neros y logos en paralelo controlado
        console.log('üîÑ Paso 7: Procesamiento por chunks (nombres, g√©neros, logos)...');
        
        const enhancedChannels = await processChannelsInChunks(
            coreProcessingResults.validatedChannels,
            {
                nameCleaningService: new ChannelNameCleaningService(),
                genreDetectionService: new GenreDetectionService(),
                logoGenerationService: new LogoGenerationService()
            }
        );
        
        console.log('‚úÖ Procesamiento por chunks completado\n');

        // DEBUG: Verificar g√©neros en enhancedChannels
        console.log('üîç DEBUG: Verificando g√©neros en enhancedChannels...');
        const genreStats = {};
        enhancedChannels.slice(0, 10).forEach((channel, index) => {
            console.log(`  Canal ${index + 1}: ${channel.name} -> G√©nero: ${channel.genre}`);
            const genre = channel.genre || 'General';
            genreStats[genre] = (genreStats[genre] || 0) + 1;
        });
        console.log('üîç DEBUG: Estad√≠sticas de g√©neros en muestra:', genreStats);
        console.log(`üîç DEBUG: Total de canales procesados: ${enhancedChannels.length}\n`);

        // FASE 8: GENERACI√ìN CSV - Escritura completamente separada y secuencial
        console.log('üìä Paso 8: Generando archivo tv.csv...');
        const csvOutputPath = config.csv?.validatedChannelsCsv || process.env.VALIDATED_CHANNELS_CSV || 'data/tv.csv';
        
        // Escribir CSV de forma completamente independiente
        console.log('   üìù Escribiendo archivo CSV...');
        const csvPath = await validatedChannelsCsvService.generateValidatedChannelsCsv(enhancedChannels);
        console.log(`   ‚úÖ CSV completado y guardado: ${csvPath}`);
        
        // Verificar que el archivo CSV se escribi√≥ correctamente antes de continuar
        const fs = await import('fs');
        if (!fs.existsSync(csvPath)) {
            throw new Error(`Error: El archivo CSV no se gener√≥ correctamente en ${csvPath}`);
        }
        console.log(`   ‚úì Verificaci√≥n CSV exitosa: archivo existe y es accesible\n`);

        // FASE 9: GENERACI√ìN M3U - Escritura completamente separada y secuencial
        console.log('üì∫ Paso 9: Generando archivos M3U...');
        
        // Esperar expl√≠citamente antes de proceder con M3U para asegurar separaci√≥n total
        console.log('   ‚è≥ Preparando generaci√≥n M3U (escritura separada)...');
        await new Promise(resolve => setTimeout(resolve, 100)); // Pausa expl√≠cita para separaci√≥n
        
        const m3uService = new M3UChannelService();
        
        // Leer canales desde el CSV ya generado para mantener orden exacto
        console.log('   üìñ Leyendo canales desde CSV generado...');
        const orderedChannelsFromCsv = await validatedChannelsCsvService.getOrderedChannelsFromCsv(csvPath);
        console.log(`   üìã Canales le√≠dos para M3U: ${orderedChannelsFromCsv.length}`);
        
        // Escribir M3U de forma completamente independiente
        console.log('   üìù Escribiendo archivo M3U...');
        await generateM3UFiles(m3uService, orderedChannelsFromCsv);
        console.log('   ‚úÖ M3U completado y guardado');

        // FASE 10: RESUMEN FINAL - Muestra estad√≠sticas completas del procesamiento
        const endTime = Date.now();
        showFinalSummary({
            rawChannels: filteredChannels.length,
            filteredChannels: filteredChannels.length,
            uniqueChannels: coreProcessingResults.uniqueChannelsCount,
            convertedChannels: coreProcessingResults.convertedChannelsCount,
            validatedChannels: enhancedChannels.length,
            csvPath,
            processingTime: endTime - startTime
        });

    } catch (error) {
        // Manejo centralizado de errores con informaci√≥n detallada
        console.error('\n‚ùå ERROR EN EL PROCESO:');
        console.error(error.message);
        console.error('\nDetalles del error:');
        console.error(error.stack);
        process.exit(1);
    }
}

/**
 * Crea un logger personalizado para el proceso
 */
/**
 * Crea un logger optimizado basado en el entorno
 * Implementa logging condicional para reducir overhead en producci√≥n
 */
function createLogger() {
    const env = process.env.NODE_ENV?.toLowerCase() || 'development';
    const logLevel = process.env.LOG_LEVEL?.toLowerCase() || 'info';
    
    // Configuraci√≥n de niveles por entorno
    const levelConfig = {
        production: { info: true, warn: true, error: true, debug: false, fatal: true },
        test: { info: false, warn: false, error: true, debug: false, fatal: true },
        development: { info: true, warn: true, error: true, debug: true, fatal: true }
    };
    
    const currentLevels = levelConfig[env] || levelConfig.development;
    
    // Override con LOG_LEVEL espec√≠fico si est√° definido
    if (logLevel === 'debug') {
        currentLevels.debug = true;
        currentLevels.info = true;
    } else if (logLevel === 'warn') {
        currentLevels.info = false;
        currentLevels.debug = false;
    } else if (logLevel === 'error') {
        currentLevels.info = false;
        currentLevels.warn = false;
        currentLevels.debug = false;
    }
    
    return {
        info: currentLevels.info ? 
            (msg, ...args) => console.log(`[INFO] ${msg}`, ...args) : 
            () => {}, // No-op en producci√≥n si est√° deshabilitado
        warn: currentLevels.warn ? 
            (msg, ...args) => console.warn(`[WARN] ${msg}`, ...args) : 
            () => {},
        error: currentLevels.error ? 
            (msg, ...args) => console.error(`[ERROR] ${msg}`, ...args) : 
            () => {},
        debug: currentLevels.debug ? 
            (msg, ...args) => console.log(`[DEBUG] ${msg}`, ...args) : 
            () => {}, // Siempre deshabilitado en producci√≥n
        fatal: currentLevels.fatal ? 
            (msg, ...args) => console.error(`[FATAL] ${msg}`, ...args) : 
            () => {}
    };
}

/**
 * Obtiene estad√≠sticas de fuentes de canales
 */
function getSourceStatistics(channels) {
    const stats = {};
    channels.forEach(channel => {
        const source = channel.source || 'unknown';
        stats[source] = (stats[source] || 0) + 1;
    });
    return stats;
}

/**
 * Registra estad√≠sticas de fuentes en el log
 */
function logSourceStatistics(sourceStats) {
    console.log('üìä Estad√≠sticas por fuente:');
    Object.entries(sourceStats)
        .sort(([,a], [,b]) => b - a)
        .forEach(([source, count]) => {
            console.log(`   - ${source}: ${count} canales`);
        });
}

/**
 * Genera archivo M3U est√°ndar en la carpeta data de forma completamente separada
 * Asegura escritura secuencial sin paralelizaci√≥n
 */
async function generateM3UFiles(m3uService, validatedChannels) {
    try {
        // Verificar que tenemos canales v√°lidos antes de proceder
        if (!validatedChannels || validatedChannels.length === 0) {
            throw new Error('No hay canales v√°lidos para generar M3U');
        }

        // Asegurar que el directorio data existe (operaci√≥n separada)
        const dataDir = 'data';
        console.log(`   üìÅ Verificando directorio: ${dataDir}`);
        await ensureDirectoryExists(dataDir);
        console.log(`   ‚úì Directorio confirmado: ${dataDir}`);

        // Generar contenido M3U (operaci√≥n separada de la escritura)
        console.log('   üîÑ Generando contenido M3U...');
        const standardM3U = await m3uService.generateM3UPlaylist({
            format: 'standard'
        }, validatedChannels);
        console.log(`   ‚úì Contenido M3U generado: ${standardM3U.length} caracteres`);

        // Escribir archivo M3U de forma completamente independiente
        const m3uFilePath = path.join(dataDir, 'channels.m3u');
        console.log(`   üíæ Escribiendo archivo M3U: ${m3uFilePath}`);
        
        // Escritura s√≠ncrona para asegurar separaci√≥n total
        await fs.writeFile(m3uFilePath, standardM3U, 'utf8');
        
        // Verificar que el archivo se escribi√≥ correctamente
        const fs_sync = await import('fs');
        if (!fs_sync.existsSync(m3uFilePath)) {
            throw new Error(`Error: El archivo M3U no se escribi√≥ correctamente en ${m3uFilePath}`);
        }
        
        console.log(`   ‚úÖ Archivo M3U guardado y verificado: ${m3uFilePath}`);
        return standardM3U; // Devolver el contenido M3U

    } catch (error) {
        console.error('   ‚ùå Error generando archivo M3U:', error.message);
        throw error;
    }
}

/**
 * Muestra el resumen final del procesamiento
 */
function showFinalSummary(stats) {
    const processingTimeSeconds = (stats.processingTime / 1000).toFixed(2);
    
    console.log('\nüéâ === PROCESO COMPLETADO EXITOSAMENTE ===');
    console.log('\nüìä Resumen del procesamiento:');
    console.log(`   üì° Canales originales: ${stats.rawChannels}`);
    console.log(`   üîç Despu√©s del filtrado: ${stats.filteredChannels}`);
    console.log(`   üîÑ Despu√©s de deduplicaci√≥n: ${stats.uniqueChannels}`);
    console.log(`   üîÑ Despu√©s de conversi√≥n: ${stats.convertedChannels}`);
    console.log(`   ‚úÖ Canales validados finales: ${stats.validatedChannels}`);
    
    console.log('\nüìÑ Archivos generados:');
    console.log(`   üìä Archivo principal: ${stats.csvPath}`);
    console.log(`   üì∫ Playlist M3U: data/channels.m3u`);
    
    console.log(`\n‚è±Ô∏è  Tiempo de procesamiento: ${processingTimeSeconds}s`);
    console.log('\nüöÄ ¬°Sistema listo para usar con Stremio!');
    console.log('üí° El archivo tv.csv contiene todos los canales validados y procesados.');
}

/**
 * Asegura que un directorio existe, cre√°ndolo si es necesario
 * @param {string} dirPath - Ruta del directorio
 */
async function ensureDirectoryExists(dirPath) {
    try {
        await fs.access(dirPath);
    } catch (error) {
        if (error.code === 'ENOENT') {
            await fs.mkdir(dirPath, { recursive: true });
            console.log(`   üìÅ Directorio creado: ${dirPath}`);
        } else {
            throw error;
        }
    }
}

/**
 * Manejo de se√±ales del sistema para cierre limpio
 */
process.on('SIGINT', () => {
    console.log('\n\n‚ö†Ô∏è  Proceso interrumpido por el usuario');
    process.exit(0);
});

process.on('SIGTERM', () => {
    console.log('\n\n‚ö†Ô∏è  Proceso terminado');
    process.exit(0);
});

// Ejecutar funci√≥n principal si este archivo es ejecutado directamente
// En Bun, verificamos si el archivo actual es el punto de entrada
const isMainModule = import.meta.main || (process.argv[1] && import.meta.url.includes(process.argv[1])) || import.meta.url.includes('main.js');

if (isMainModule) {
    const startTime = Date.now();
    main().then(() => {
        const totalTime = ((Date.now() - startTime) / 1000).toFixed(2);
        console.log(`\n‚è±Ô∏è  Tiempo total de ejecuci√≥n: ${totalTime}s`);
    }).catch(error => {
        console.error('\nüí• Error fatal:', error);
        process.exit(1);
    });
}

/**
 * Procesador unificado para resultados de Promise.allSettled - Elimina duplicaci√≥n y mejora estabilidad
 * ACTUALIZADO: Manejo mejorado de errores cr√≠ticos vs no cr√≠ticos
 * @param {Array} baseChannels - Canales base para procesar
 * @param {Object} results - Resultados de deduplicaci√≥n, conversi√≥n y validaci√≥n
 * @returns {Object} Canales procesados y estad√≠sticas consolidadas
 */
function processParallelResults(baseChannels, { deduplicatedResult, conversionResult, validationResult }) {
    let processedChannels = baseChannels; // Canales que van siendo transformados
    let uniqueChannelsCount = baseChannels.length;
    let convertedChannelsCount = baseChannels.length;
    
    // Procesador de deduplicaci√≥n con manejo robusto de errores
    if (deduplicatedResult.status === 'fulfilled') {
        const uniqueChannels = deduplicatedResult.value.channels;
        const deduplicationStats = calculateDeduplicationStats(baseChannels.length, uniqueChannels.length);
        
        console.log(`üìä Canales √∫nicos: ${uniqueChannels.length} (${deduplicationStats.efficiency}% √∫nicos)`);
        console.log(`üóëÔ∏è  Duplicados eliminados: ${deduplicationStats.duplicatesRemoved}`);
        
        processedChannels = uniqueChannels; // Aplicar deduplicaci√≥n
        uniqueChannelsCount = uniqueChannels.length;
    } else {
        // NOTA: Los errores cr√≠ticos ya fueron manejados con fail-fast en el flujo principal
        console.error(`‚ùå Error en deduplicaci√≥n (ya manejado): ${deduplicatedResult.reason?.message}`);
    }

    // Procesador de conversi√≥n HTTPS‚ÜíHTTP con actualizaci√≥n inteligente
    if (conversionResult.status === 'fulfilled') {
        const convertedChannels = conversionResult.value.processed;
        console.log(`üìä Canales procesados para conversi√≥n: ${convertedChannels.length}`);
        console.log(`üîÑ Conversiones HTTPS‚ÜíHTTP: ${conversionResult.value.stats.converted}`);
        console.log(`‚úÖ URLs HTTP funcionales: ${conversionResult.value.stats.httpWorking}`);
        
        // Aplicar conversiones manteniendo integridad de datos
        processedChannels = applyChannelUpdates(processedChannels, convertedChannels);
        convertedChannelsCount = processedChannels.length;
    } else {
        // NOTA: Los errores cr√≠ticos ya fueron manejados con fail-fast en el flujo principal
        console.error(`‚ùå Error en conversi√≥n (ya manejado): ${conversionResult.reason?.message}`);
    }

    // Procesador de validaci√≥n con filtrado seguro y fallback mejorado
    if (validationResult.status === 'fulfilled') {
        const { validChannels, invalidChannels, stats } = validationResult.value;
        
        // Filtrar solo canales validados manteniendo consistencia
        processedChannels = processedChannels.filter(channel => 
            validChannels.some(valid => valid.id === channel.id)
        );
        
        console.log(`üìä Canales validados: ${processedChannels.length} (${invalidChannels.length} inv√°lidos)`);
        
        if (stats.processingTime) {
            console.log(`‚è±Ô∏è  Tiempo de validaci√≥n: ${(stats.processingTime/1000).toFixed(1)}s`);
        }
    } else {
        // Para validaci√≥n, usar fallback si est√° disponible (error no cr√≠tico)
        if (validationResult.fallback) {
            console.warn(`‚ö†Ô∏è  Usando fallback para validaci√≥n: todos los canales marcados como v√°lidos`);
            // No filtrar canales, mantener todos como v√°lidos por defecto
        } else {
            console.error(`‚ùå Error en validaci√≥n sin fallback: ${validationResult.reason?.message}`);
        }
    }

    return {
        validatedChannels: processedChannels,
        uniqueChannelsCount,
        convertedChannelsCount
    };
}

/**
 * Calcula estad√≠sticas de deduplicaci√≥n de forma consistente
 * @param {number} before - Cantidad antes de deduplicar
 * @param {number} after - Cantidad despu√©s de deduplicar
 * @returns {Object} Estad√≠sticas calculadas
 */
function calculateDeduplicationStats(before, after) {
    return {
        beforeDedup: before,
        afterDedup: after,
        duplicatesRemoved: before - after,
        efficiency: ((after / before) * 100).toFixed(1)
    };
}

/**
 * Aplica actualizaciones de canales de forma segura evitando p√©rdida de datos
 * @param {Array} baseChannels - Canales base
 * @param {Array} updatedChannels - Canales con actualizaciones
 * @returns {Array} Canales con actualizaciones aplicadas
 */
function applyChannelUpdates(baseChannels, updatedChannels) {
    return baseChannels.map(channel => {
        const updated = updatedChannels.find(c => c.id === channel.id);
        return updated || channel; // Usar versi√≥n actualizada si existe, sino mantener original
    });
}

/**
 * Asigna IDs √∫nicos a canales que no los tengan
 * @param {Array} channels - Array de canales
 * @returns {Array} Canales con IDs √∫nicos asignados
 */
function assignUniqueIds(channels) {
    return channels.map((channel, index) => {
        // Manejar instancias de la clase Channel que usan propiedades privadas
        if (channel.constructor.name === 'Channel') {
            return {
                id: channel.id || `channel_${Date.now()}_${index}`,
                name: channel.name,
                streamUrl: channel.streamUrl,
                logo: channel.logo,
                genre: channel.genre,
                country: channel.country,
                language: channel.language,
                quality: channel.quality,
                type: channel.type,
                isActive: channel.isActive,
                metadata: channel.metadata,
                originalIndex: index
            };
        }
        
        // Para objetos planos usar spread operator
        return {
            ...channel,
            id: channel.id || `channel_${Date.now()}_${index}`,
            originalIndex: index
        };
    });
}

/**
 * Procesa canales en chunks para optimizar rendimiento y mantener funcionalidades
 * @param {Array} channels - Canales a procesar
 * @param {Object} services - Servicios de procesamiento
 * @returns {Array} Canales procesados con todas las mejoras aplicadas
 */
async function processChannelsInChunks(channels, services) {
    const { nameCleaningService, genreDetectionService, logoGenerationService } = services;
    const CHUNK_SIZE = 15; // Tama√±o √≥ptimo para procesamiento paralelo
    
    // Dividir canales en chunks
    const chunks = [];
    for (let i = 0; i < channels.length; i += CHUNK_SIZE) {
        chunks.push(channels.slice(i, i + CHUNK_SIZE));
    }
    
    console.log(`   üì¶ Procesando ${channels.length} canales en ${chunks.length} chunks de ${CHUNK_SIZE}`);
    
    // Asegurar directorio de logos
    await logoGenerationService.ensureLogoDirectory();
    
    // Procesar chunks en paralelo
    const processedChunks = await Promise.all(
        chunks.map(async (chunk, chunkIndex) => {
            console.log(`   üîÑ Procesando chunk ${chunkIndex + 1}/${chunks.length} (${chunk.length} canales)`);
            
            // Procesar cada chunk de forma secuencial para mantener consistencia
            let processedChunk = [...chunk];
            
            // DEBUG: Verificar canales antes del procesamiento
            console.log(`     üîç DEBUG Chunk ${chunkIndex}: Canales antes del procesamiento:`);
            processedChunk.slice(0, 3).forEach((channel, idx) => {
                console.log(`       Canal ${idx + 1}: ${channel.name} -> G√©nero: ${channel.genre}`);
            });
            
            // 1. Limpieza de nombres
            processedChunk = await nameCleaningService.processChannelsInBatches(processedChunk);
            
            // DEBUG: Verificar canales despu√©s de limpieza de nombres
            console.log(`     üîç DEBUG Chunk ${chunkIndex}: Canales despu√©s de limpieza:`);
            processedChunk.slice(0, 3).forEach((channel, idx) => {
                console.log(`       Canal ${idx + 1}: ${channel.name} -> G√©nero: ${channel.genre}`);
            });

            // 2. Detecci√≥n de g√©neros
            const genreResults = genreDetectionService.processChannels(processedChunk);
            processedChunk = genreResults.channels; // Los g√©neros ya est√°n aplicados en cada canal
            
            // DEBUG: Verificar canales despu√©s de detecci√≥n de g√©neros
            console.log(`     üîç DEBUG Chunk ${chunkIndex}: Canales despu√©s de g√©neros:`);
            processedChunk.slice(0, 3).forEach((channel, idx) => {
                console.log(`       Canal ${idx + 1}: ${channel.name} -> G√©nero: ${channel.genre}`);
            });
            
            // 3. Generaci√≥n de logos
            const channelsForLogos = processedChunk.map(channel => ({
                id: channel.id,
                name: channel.name || `Canal ${channel.originalIndex + 1}`
            }));
            
            const logoResults = await logoGenerationService.generateMultipleLogos(channelsForLogos);
            
            // 4. Integraci√≥n de logos
            const logoMap = new Map();
            logoResults.forEach(result => {
                if (result.success && result.logoPath) {
                    logoMap.set(result.channelId, result.logoPath);
                }
            });
            
            // Aplicar logos a canales
            processedChunk.forEach(channel => {
                const logoPath = logoMap.get(channel.id);
                if (logoPath) {
                    const relativePath = path.relative(process.cwd(), logoPath).replace(/\\/g, '/');
                    channel.logo = relativePath;
                }
            });
            
            return {
                channels: processedChunk,
                stats: {
                    chunkIndex,
                    processed: processedChunk.length,
                    logosGenerated: logoResults.filter(r => r.success).length,
                    genreStats: genreResults.stats
                }
            };
        })
    );
    
    // Consolidar resultados
    const allProcessedChannels = processedChunks.flatMap(chunk => chunk.channels);
    
    // DEBUG: Verificar contenido de processedChunks
    console.log('üîç DEBUG processChannelsInChunks: Verificando chunks procesados...');
    processedChunks.slice(0, 2).forEach((chunk, chunkIndex) => {
        console.log(`  Chunk ${chunkIndex}: ${chunk.channels.length} canales`);
        chunk.channels.slice(0, 3).forEach((channel, channelIndex) => {
            console.log(`    Canal ${channelIndex + 1}: ${channel.name} -> G√©nero: ${channel.genre}`);
        });
    });
    console.log(`üîç DEBUG: Total allProcessedChannels: ${allProcessedChannels.length}`);
    console.log('üîç DEBUG: Muestra de allProcessedChannels:');
    allProcessedChannels.slice(0, 5).forEach((channel, index) => {
        console.log(`  Canal ${index + 1}: ${channel.name} -> G√©nero: ${channel.genre}`);
    });
    
    // Estad√≠sticas consolidadas
    const totalLogosGenerated = processedChunks.reduce((sum, chunk) => sum + chunk.stats.logosGenerated, 0);
    const cleaningMetrics = nameCleaningService.getMetrics();
    
    // Consolidar estad√≠sticas de g√©neros
    const allGenreStats = processedChunks.map(chunk => chunk.stats.genreStats);
    const consolidatedGenreStats = consolidateGenreStats(allGenreStats);
    
    console.log(`   ‚úÖ Limpieza: ${cleaningMetrics.totalCleaned}/${cleaningMetrics.totalProcessed} nombres (${cleaningMetrics.cleaningRate}%)`);
    console.log(`   ‚úÖ G√©neros: ${consolidatedGenreStats.totalGenres} √∫nicos detectados`);
    console.log(`   ‚úÖ Logos: ${totalLogosGenerated}/${allProcessedChannels.length} generados`);
    
    return allProcessedChannels;
}

/**
 * Consolida estad√≠sticas de g√©neros de m√∫ltiples chunks
 * @param {Array} genreStatsArray - Array de estad√≠sticas de g√©neros
 * @returns {Object} Estad√≠sticas consolidadas
 */
function consolidateGenreStats(genreStatsArray) {
    const allGenres = new Set();
    let totalChannelsWithGenres = 0;
    const genreCounts = new Map();
    
    genreStatsArray.forEach(stats => {
        if (stats && stats.topGenres) {
            stats.topGenres.forEach(([genre, count]) => {
                allGenres.add(genre);
                genreCounts.set(genre, (genreCounts.get(genre) || 0) + count);
            });
        }
        if (stats && stats.totalChannelsWithGenres) {
            totalChannelsWithGenres += stats.totalChannelsWithGenres;
        }
    });
    
    const topGenres = Array.from(genreCounts.entries())
        .sort(([,a], [,b]) => b - a)
        .slice(0, 10);
    
    return {
        totalGenres: allGenres.size,
        totalChannelsWithGenres,
        topGenres,
        avgGenresPerChannel: totalChannelsWithGenres > 0 ? (allGenres.size / totalChannelsWithGenres).toFixed(2) : 0
    };
}

export { main };